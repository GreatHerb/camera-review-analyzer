"""
datapipe/analyze_keywords.py

- review í…Œì´ë¸”ì—ì„œ ì¹´ë©”ë¼ + ê°ì„±ë³„ë¡œ ë¦¬ë·°ë¥¼ ëª¨ì•„
  ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë¶„ì„(ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´) í›„
  review_keyword_stats í…Œì´ë¸”ì— ì €ì¥.

ì‹¤í–‰ ë°©ë²•:

  cd datapipe
  source .venv/bin/activate
  python analyze_keywords.py
"""

import os
import re
from collections import Counter
from datetime import datetime

from sqlalchemy import create_engine, text


# ---------- DB ì„¤ì • ----------

DB_URL = os.environ.get(
    "DATABASE_URL",
    "postgresql+psycopg2://devuser:devpass@localhost:5432/camera_reviews",
)
engine = create_engine(DB_URL, future=True)


# ---------- ê°„ë‹¨ í† í°í™” / ë¶ˆìš©ì–´ ----------

# ë„ˆë¬´ ë‹¹ì—°í•œ ë‹¨ì–´, ë…¸ì´ì¦ˆ ë‹¨ì–´ëŠ” ì œê±° (ì›í•˜ëŠ” ëŒ€ë¡œ ê³„ì† ì¶”ê°€ ê°€ëŠ¥)
STOPWORDS = {
    "ì˜ìƒ", "ë¦¬ë·°", "ì¹´ë©”ë¼", "ì‚¬ì§„", "í›„ê¸°",
    "ì§„ì§œ", "ì •ë§", "ì¡°ê¸ˆ", "ê±°ì˜", "ë³´ê³ ",
    "ì´ê±°", "ì €ê±°", "ê·¸ëƒ¥", "ì‚¬ìš©", "ì‚¬ìš©ê¸°",
    "ìœ íŠœë¸Œ", "ì±„ë„", "êµ¬ë…", "ê°ì‚¬", "ì„¤ëª…",
}


def tokenize(text: str):
    """
    ë§¤ìš° ë‹¨ìˆœí•œ í•œêµ­ì–´ í† í°í™”:
      - íŠ¹ìˆ˜ë¬¸ì ì œê±°
      - ê³µë°± ê¸°ì¤€ split
      - 1ê¸€ì í† í°, ë¶ˆìš©ì–´ ì œê±°
    """
    if not text:
        return []

    # í•œê¸€/ì˜ì–´/ìˆ«ì/ê³µë°±ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ê³µë°± ì²˜ë¦¬
    text = re.sub(r"[^0-9ê°€-í£A-Za-z\s]", " ", text)
    tokens = text.split()

    cleaned = []
    for tok in tokens:
        tok = tok.strip()
        if len(tok) <= 1:
            continue
        if tok in STOPWORDS:
            continue
        cleaned.append(tok)

    return cleaned


# ---------- ë©”ì¸ ë¡œì§ ----------

SELECT_SQL = text(
    """
    SELECT id, camera_model, sentiment_label, content
      FROM review
     WHERE sentiment_label IS NOT NULL
       AND TRIM(sentiment_label) <> ''
       AND camera_model IS NOT NULL
       AND TRIM(camera_model) <> ''
       AND content IS NOT NULL
       AND TRIM(content) <> ''
"""
)

DELETE_SQL = text("DELETE FROM review_keyword_stats")

INSERT_SQL = text(
    """
    INSERT INTO review_keyword_stats (
        camera_model, sentiment_label, keyword, freq, updated_at
    ) VALUES (
        :camera_model, :sentiment_label, :keyword, :freq, :updated_at
    )
"""
)


def main(top_k: int = 30):
    """
    ì¹´ë©”ë¼ ê¸°ì¢… + ê°ì„±ë³„ë¡œ top_k í‚¤ì›Œë“œë¥¼ ì§‘ê³„í•˜ì—¬ review_keyword_statsì— ì €ì¥
    """
    with engine.begin() as conn:
        rows = conn.execute(SELECT_SQL).mappings().all()
        print(f"ğŸ” í‚¤ì›Œë“œ ë¶„ì„ ëŒ€ìƒ ë¦¬ë·° ìˆ˜: {len(rows)}")

        if not rows:
            print("ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # (camera_model, sentiment_label) -> [content, content, ...]
        groups = {}
        for r in rows:
            key = (r["camera_model"], r["sentiment_label"])
            groups.setdefault(key, []).append(r["content"] or "")

        print(f"ğŸ“‚ ì¹´ë©”ë¼/ê°ì„± ì¡°í•© ê°œìˆ˜: {len(groups)}")

        # ê¸°ì¡´ í†µê³„ ì‚­ì œ
        conn.execute(DELETE_SQL)

        now = datetime.utcnow()
        total_inserted = 0

        for (camera, sentiment), contents in groups.items():
            counter = Counter()

            for content in contents:
                tokens = tokenize(content)
                counter.update(tokens)

            # ìƒìœ„ top_k ê°œë§Œ ì €ì¥
            for keyword, freq in counter.most_common(top_k):
                conn.execute(
                    INSERT_SQL,
                    {
                        "camera_model": camera,
                        "sentiment_label": sentiment,
                        "keyword": keyword,
                        "freq": int(freq),
                        "updated_at": now,
                    },
                )
                total_inserted += 1

            print(
                f"  â–¶ {camera} / {sentiment}: {len(counter)}ê°œ í† í° ì¤‘ ìƒìœ„ {top_k} ì €ì¥"
            )

    print(f"âœ… í‚¤ì›Œë“œ í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ì´ {total_inserted}í–‰ ì‚½ì…")


if __name__ == "__main__":
    main()